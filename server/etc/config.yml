#config for asr using whisper API
openai:
    openAiStub: false #save money or not!
    oldWhisperKey: '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'
    whisperKey: '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'
    whisperApiUrl: 'https://api.openai.com/v1/audio/transcriptions'
audio:
    sampleRate: 16000
    chunkTime: 0.03 # 10,20,30 ms for vad detection
    sampleWidth: 2 #np.int16 width
    dType : 'np.int16'
    channels: 2 #2-stereo or 1-mono. we only use one channel for Voice now

whisperApiAlg: #algorithm parameters
    duration: 5.5 #max audio time for transcription 
    debugMp3i: true #writes out audio and transcript to debugDir
    debugDir: '/home/vv/dbg'
    NvadLead: 3 # max nvad sequence to send to transcribe. Larger nvad sequences are reduced to this
    BufferTime: 30 #Max seconds of audio is kept in buffer
    ignoreShortAudioTime: 0.3 #ignore audio segements less that this seconds


